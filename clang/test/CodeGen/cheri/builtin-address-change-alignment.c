// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py UTC_ARGS: --function-signature
// RUN: %cheri_purecap_cc1 -o - -emit-llvm %s | FileCheck %s
/// After overloading all CHERI builtins, __builtin_cheri_offset_increment,
/// __builtin_cheri_address_set and __builtin_cheri_offset_set could cause
/// some pointer to incorrectly be marked as aligned due to clang using the
/// new type information.
struct AlignedAsCap {
  char buffer[16];
  __uintcap_t cap;
};

// CHECK-LABEL: define {{[^@]+}}@check_alignment_memcpy_inc_offset
// CHECK-SAME: (ptr addrspace(200) noundef [[TMPBUFFER:%.*]], ptr addrspace(200) noundef [[A:%.*]]) addrspace(200) #[[ATTR0:[0-9]+]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMPBUFFER_ADDR:%.*]] = alloca ptr addrspace(200), align 16, addrspace(200)
// CHECK-NEXT:    [[A_ADDR:%.*]] = alloca ptr addrspace(200), align 16, addrspace(200)
// CHECK-NEXT:    store ptr addrspace(200) [[TMPBUFFER]], ptr addrspace(200) [[TMPBUFFER_ADDR]], align 16
// CHECK-NEXT:    store ptr addrspace(200) [[A]], ptr addrspace(200) [[A_ADDR]], align 16
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr addrspace(200), ptr addrspace(200) [[TMPBUFFER_ADDR]], align 16
// CHECK-NEXT:    [[TMP1:%.*]] = load ptr addrspace(200), ptr addrspace(200) [[A_ADDR]], align 16
// CHECK-NEXT:    [[__BUILTIN_CHERI_OFFSET_INCREMENT:%.*]] = getelementptr i8, ptr addrspace(200) [[TMP1]], i64 4
// CHECK-NEXT:    call void @llvm.memcpy.p200.p200.i64(ptr addrspace(200) align 1 [[TMP0]], ptr addrspace(200) align 1 [[__BUILTIN_CHERI_OFFSET_INCREMENT]], i64 16, i1 false)
// CHECK-NEXT:    ret void
//
void check_alignment_memcpy_inc_offset(void *tmpbuffer, struct AlignedAsCap *a) {
  __builtin_memcpy(tmpbuffer, __builtin_cheri_offset_increment(a, 4), sizeof(__uintcap_t));
}

// CHECK-LABEL: define {{[^@]+}}@check_alignment_memcpy_set_offset
// CHECK-SAME: (ptr addrspace(200) noundef [[TMPBUFFER:%.*]], ptr addrspace(200) noundef [[A:%.*]], i64 noundef signext [[NEW_OFFSET:%.*]]) addrspace(200) #[[ATTR0]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMPBUFFER_ADDR:%.*]] = alloca ptr addrspace(200), align 16, addrspace(200)
// CHECK-NEXT:    [[A_ADDR:%.*]] = alloca ptr addrspace(200), align 16, addrspace(200)
// CHECK-NEXT:    [[NEW_OFFSET_ADDR:%.*]] = alloca i64, align 8, addrspace(200)
// CHECK-NEXT:    store ptr addrspace(200) [[TMPBUFFER]], ptr addrspace(200) [[TMPBUFFER_ADDR]], align 16
// CHECK-NEXT:    store ptr addrspace(200) [[A]], ptr addrspace(200) [[A_ADDR]], align 16
// CHECK-NEXT:    store i64 [[NEW_OFFSET]], ptr addrspace(200) [[NEW_OFFSET_ADDR]], align 8
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr addrspace(200), ptr addrspace(200) [[TMPBUFFER_ADDR]], align 16
// CHECK-NEXT:    [[TMP1:%.*]] = load ptr addrspace(200), ptr addrspace(200) [[A_ADDR]], align 16
// CHECK-NEXT:    [[TMP2:%.*]] = load i64, ptr addrspace(200) [[NEW_OFFSET_ADDR]], align 8
// CHECK-NEXT:    [[TMP3:%.*]] = call ptr addrspace(200) @llvm.cheri.cap.offset.set.i64(ptr addrspace(200) [[TMP1]], i64 [[TMP2]])
// CHECK-NEXT:    call void @llvm.memcpy.p200.p200.i64(ptr addrspace(200) align 1 [[TMP0]], ptr addrspace(200) align 1 [[TMP3]], i64 16, i1 false)
// CHECK-NEXT:    ret void
//
void check_alignment_memcpy_set_offset(void *tmpbuffer, struct AlignedAsCap *a, long new_offset) {
  __builtin_memcpy(tmpbuffer, __builtin_cheri_offset_set(a, new_offset), sizeof(__uintcap_t));
}

// CHECK-LABEL: define {{[^@]+}}@check_alignment_memcpy_set_address
// CHECK-SAME: (ptr addrspace(200) noundef [[TMPBUFFER:%.*]], ptr addrspace(200) noundef [[A:%.*]], i64 noundef signext [[NEW_ADDR:%.*]]) addrspace(200) #[[ATTR0]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMPBUFFER_ADDR:%.*]] = alloca ptr addrspace(200), align 16, addrspace(200)
// CHECK-NEXT:    [[A_ADDR:%.*]] = alloca ptr addrspace(200), align 16, addrspace(200)
// CHECK-NEXT:    [[NEW_ADDR_ADDR:%.*]] = alloca i64, align 8, addrspace(200)
// CHECK-NEXT:    store ptr addrspace(200) [[TMPBUFFER]], ptr addrspace(200) [[TMPBUFFER_ADDR]], align 16
// CHECK-NEXT:    store ptr addrspace(200) [[A]], ptr addrspace(200) [[A_ADDR]], align 16
// CHECK-NEXT:    store i64 [[NEW_ADDR]], ptr addrspace(200) [[NEW_ADDR_ADDR]], align 8
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr addrspace(200), ptr addrspace(200) [[TMPBUFFER_ADDR]], align 16
// CHECK-NEXT:    [[TMP1:%.*]] = load ptr addrspace(200), ptr addrspace(200) [[A_ADDR]], align 16
// CHECK-NEXT:    [[TMP2:%.*]] = load i64, ptr addrspace(200) [[NEW_ADDR_ADDR]], align 8
// CHECK-NEXT:    [[TMP3:%.*]] = call ptr addrspace(200) @llvm.cheri.cap.address.set.i64(ptr addrspace(200) [[TMP1]], i64 [[TMP2]])
// CHECK-NEXT:    call void @llvm.memcpy.p200.p200.i64(ptr addrspace(200) align 1 [[TMP0]], ptr addrspace(200) align 1 [[TMP3]], i64 16, i1 false)
// CHECK-NEXT:    ret void
//
void check_alignment_memcpy_set_address(void *tmpbuffer, struct AlignedAsCap *a, long new_addr) {
  __builtin_memcpy(tmpbuffer, __builtin_cheri_address_set(a, new_addr), sizeof(__uintcap_t));
}

/// Check that we don't generate a bad cast instruction when returning the
/// result (this would assert if we were to retain the type in codegen).

// CHECK-LABEL: define {{[^@]+}}@check_return_inc_offset
// CHECK-SAME: (ptr addrspace(200) noundef [[A:%.*]]) addrspace(200) #[[ATTR0]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[A_ADDR:%.*]] = alloca ptr addrspace(200), align 16, addrspace(200)
// CHECK-NEXT:    store ptr addrspace(200) [[A]], ptr addrspace(200) [[A_ADDR]], align 16
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr addrspace(200), ptr addrspace(200) [[A_ADDR]], align 16
// CHECK-NEXT:    [[__BUILTIN_CHERI_OFFSET_INCREMENT:%.*]] = getelementptr i8, ptr addrspace(200) [[TMP0]], i64 4
// CHECK-NEXT:    ret ptr addrspace(200) [[__BUILTIN_CHERI_OFFSET_INCREMENT]]
//
void *check_return_inc_offset(struct AlignedAsCap *a) {
  return __builtin_cheri_offset_increment(a, 4);
}

// CHECK-LABEL: define {{[^@]+}}@check_return_set_offset
// CHECK-SAME: (ptr addrspace(200) noundef [[A:%.*]], i64 noundef signext [[NEW_OFFSET:%.*]]) addrspace(200) #[[ATTR0]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[A_ADDR:%.*]] = alloca ptr addrspace(200), align 16, addrspace(200)
// CHECK-NEXT:    [[NEW_OFFSET_ADDR:%.*]] = alloca i64, align 8, addrspace(200)
// CHECK-NEXT:    store ptr addrspace(200) [[A]], ptr addrspace(200) [[A_ADDR]], align 16
// CHECK-NEXT:    store i64 [[NEW_OFFSET]], ptr addrspace(200) [[NEW_OFFSET_ADDR]], align 8
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr addrspace(200), ptr addrspace(200) [[A_ADDR]], align 16
// CHECK-NEXT:    [[TMP1:%.*]] = load i64, ptr addrspace(200) [[NEW_OFFSET_ADDR]], align 8
// CHECK-NEXT:    [[TMP2:%.*]] = call ptr addrspace(200) @llvm.cheri.cap.offset.set.i64(ptr addrspace(200) [[TMP0]], i64 [[TMP1]])
// CHECK-NEXT:    ret ptr addrspace(200) [[TMP2]]
//
void *check_return_set_offset(struct AlignedAsCap *a, long new_offset) {
  return __builtin_cheri_offset_set(a, new_offset);
}

// CHECK-LABEL: define {{[^@]+}}@check_return_set_addr
// CHECK-SAME: (ptr addrspace(200) noundef [[A:%.*]], i64 noundef signext [[NEW_ADDR:%.*]]) addrspace(200) #[[ATTR0]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[A_ADDR:%.*]] = alloca ptr addrspace(200), align 16, addrspace(200)
// CHECK-NEXT:    [[NEW_ADDR_ADDR:%.*]] = alloca i64, align 8, addrspace(200)
// CHECK-NEXT:    store ptr addrspace(200) [[A]], ptr addrspace(200) [[A_ADDR]], align 16
// CHECK-NEXT:    store i64 [[NEW_ADDR]], ptr addrspace(200) [[NEW_ADDR_ADDR]], align 8
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr addrspace(200), ptr addrspace(200) [[A_ADDR]], align 16
// CHECK-NEXT:    [[TMP1:%.*]] = load i64, ptr addrspace(200) [[NEW_ADDR_ADDR]], align 8
// CHECK-NEXT:    [[TMP2:%.*]] = call ptr addrspace(200) @llvm.cheri.cap.address.set.i64(ptr addrspace(200) [[TMP0]], i64 [[TMP1]])
// CHECK-NEXT:    ret ptr addrspace(200) [[TMP2]]
//
void *check_return_set_addr(struct AlignedAsCap *a, long new_addr) {
  return __builtin_cheri_address_set(a, new_addr);
}

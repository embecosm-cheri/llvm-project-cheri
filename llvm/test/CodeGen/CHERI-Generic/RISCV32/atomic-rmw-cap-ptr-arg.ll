; NOTE: Assertions have been autogenerated by utils/update_test_checks.py UTC_ARGS: --function-signature --scrub-attributes --force-update
; DO NOT EDIT -- This file was generated from test/CodeGen/CHERI-Generic/Inputs/atomic-rmw-cap-ptr-arg.ll
; Check that we can generate sensible code for atomic operations using capability pointers on capabilities
; See https://github.com/CTSRD-CHERI/llvm-project/issues/470
; RUN: llc -mtriple=riscv32 --relocation-model=pic -target-abi il32pc64f -mattr=+xcheri,+cap-mode,+f -mattr=+a < %s | FileCheck %s --check-prefixes=PURECAP,PURECAP-ATOMICS --allow-unused-prefixes
; RUN: llc -mtriple=riscv32 --relocation-model=pic -target-abi il32pc64f -mattr=+xcheri,+cap-mode,+f -mattr=-a < %s | FileCheck %s --check-prefixes=PURECAP,PURECAP-LIBCALLS --allow-unused-prefixes
; RUN: llc -mtriple=riscv32 --relocation-model=pic -target-abi ilp32f -mattr=+xcheri,+f -mattr=+a < %s | FileCheck %s --check-prefixes=HYBRID,HYBRID-ATOMICS --allow-unused-prefixes
; RUN: llc -mtriple=riscv32 --relocation-model=pic -target-abi ilp32f -mattr=+xcheri,+f -mattr=-a < %s | FileCheck %s --check-prefixes=HYBRID,HYBRID-LIBCALLS --allow-unused-prefixes

define i32 addrspace(200)* @atomic_cap_ptr_xchg_sc(i32 addrspace(200)* addrspace(200)* %ptr, i32 addrspace(200)* %val) nounwind {
; PURECAP-ATOMICS-LABEL: atomic_cap_ptr_xchg_sc:
; PURECAP-ATOMICS:       # %bb.0:
; PURECAP-ATOMICS-NEXT:    camoswap.c.aqrl ca0, ca1, (ca0)
; PURECAP-ATOMICS-NEXT:    cret
;
; PURECAP-LIBCALLS-LABEL: atomic_cap_ptr_xchg_sc:
; PURECAP-LIBCALLS:       # %bb.0:
; PURECAP-LIBCALLS-NEXT:    cincoffset csp, csp, -16
; PURECAP-LIBCALLS-NEXT:    csc cra, 8(csp) # 8-byte Folded Spill
; PURECAP-LIBCALLS-NEXT:    li a2, 5
; PURECAP-LIBCALLS-NEXT:    ccall __atomic_exchange_cap
; PURECAP-LIBCALLS-NEXT:    clc cra, 8(csp) # 8-byte Folded Reload
; PURECAP-LIBCALLS-NEXT:    cincoffset csp, csp, 16
; PURECAP-LIBCALLS-NEXT:    cret
;
; HYBRID-LABEL: atomic_cap_ptr_xchg_sc:
; HYBRID:       # %bb.0:
; HYBRID-NEXT:    addi sp, sp, -16
; HYBRID-NEXT:    sw ra, 12(sp) # 4-byte Folded Spill
; HYBRID-NEXT:    li a2, 5
; HYBRID-NEXT:    call __atomic_exchange_cap_c@plt
; HYBRID-NEXT:    lw ra, 12(sp) # 4-byte Folded Reload
; HYBRID-NEXT:    addi sp, sp, 16
; HYBRID-NEXT:    ret
  %tmp = atomicrmw xchg i32 addrspace(200)* addrspace(200)* %ptr, i32 addrspace(200)* %val seq_cst
  ret i32 addrspace(200)* %tmp
}

define i32 addrspace(200)* @atomic_cap_ptr_xchg_relaxed(i32 addrspace(200)* addrspace(200)* %ptr, i32 addrspace(200)* %val) nounwind {
; PURECAP-ATOMICS-LABEL: atomic_cap_ptr_xchg_relaxed:
; PURECAP-ATOMICS:       # %bb.0:
; PURECAP-ATOMICS-NEXT:    camoswap.c ca0, ca1, (ca0)
; PURECAP-ATOMICS-NEXT:    cret
;
; PURECAP-LIBCALLS-LABEL: atomic_cap_ptr_xchg_relaxed:
; PURECAP-LIBCALLS:       # %bb.0:
; PURECAP-LIBCALLS-NEXT:    cincoffset csp, csp, -16
; PURECAP-LIBCALLS-NEXT:    csc cra, 8(csp) # 8-byte Folded Spill
; PURECAP-LIBCALLS-NEXT:    li a2, 0
; PURECAP-LIBCALLS-NEXT:    ccall __atomic_exchange_cap
; PURECAP-LIBCALLS-NEXT:    clc cra, 8(csp) # 8-byte Folded Reload
; PURECAP-LIBCALLS-NEXT:    cincoffset csp, csp, 16
; PURECAP-LIBCALLS-NEXT:    cret
;
; HYBRID-LABEL: atomic_cap_ptr_xchg_relaxed:
; HYBRID:       # %bb.0:
; HYBRID-NEXT:    addi sp, sp, -16
; HYBRID-NEXT:    sw ra, 12(sp) # 4-byte Folded Spill
; HYBRID-NEXT:    li a2, 0
; HYBRID-NEXT:    call __atomic_exchange_cap_c@plt
; HYBRID-NEXT:    lw ra, 12(sp) # 4-byte Folded Reload
; HYBRID-NEXT:    addi sp, sp, 16
; HYBRID-NEXT:    ret
  %tmp = atomicrmw xchg i32 addrspace(200)* addrspace(200)* %ptr, i32 addrspace(200)* %val monotonic
  ret i32 addrspace(200)* %tmp
}

define i32 addrspace(200)* @atomic_cap_ptr_xchg_acquire(i32 addrspace(200)* addrspace(200)* %ptr, i32 addrspace(200)* %val) nounwind {
; PURECAP-ATOMICS-LABEL: atomic_cap_ptr_xchg_acquire:
; PURECAP-ATOMICS:       # %bb.0:
; PURECAP-ATOMICS-NEXT:    camoswap.c.aq ca0, ca1, (ca0)
; PURECAP-ATOMICS-NEXT:    cret
;
; PURECAP-LIBCALLS-LABEL: atomic_cap_ptr_xchg_acquire:
; PURECAP-LIBCALLS:       # %bb.0:
; PURECAP-LIBCALLS-NEXT:    cincoffset csp, csp, -16
; PURECAP-LIBCALLS-NEXT:    csc cra, 8(csp) # 8-byte Folded Spill
; PURECAP-LIBCALLS-NEXT:    li a2, 2
; PURECAP-LIBCALLS-NEXT:    ccall __atomic_exchange_cap
; PURECAP-LIBCALLS-NEXT:    clc cra, 8(csp) # 8-byte Folded Reload
; PURECAP-LIBCALLS-NEXT:    cincoffset csp, csp, 16
; PURECAP-LIBCALLS-NEXT:    cret
;
; HYBRID-LABEL: atomic_cap_ptr_xchg_acquire:
; HYBRID:       # %bb.0:
; HYBRID-NEXT:    addi sp, sp, -16
; HYBRID-NEXT:    sw ra, 12(sp) # 4-byte Folded Spill
; HYBRID-NEXT:    li a2, 2
; HYBRID-NEXT:    call __atomic_exchange_cap_c@plt
; HYBRID-NEXT:    lw ra, 12(sp) # 4-byte Folded Reload
; HYBRID-NEXT:    addi sp, sp, 16
; HYBRID-NEXT:    ret
  %tmp = atomicrmw xchg i32 addrspace(200)* addrspace(200)* %ptr, i32 addrspace(200)* %val acquire
  ret i32 addrspace(200)* %tmp
}

define i32 addrspace(200)* @atomic_cap_ptr_xchg_rel(i32 addrspace(200)* addrspace(200)* %ptr, i32 addrspace(200)* %val) nounwind {
; PURECAP-ATOMICS-LABEL: atomic_cap_ptr_xchg_rel:
; PURECAP-ATOMICS:       # %bb.0:
; PURECAP-ATOMICS-NEXT:    camoswap.c.rl ca0, ca1, (ca0)
; PURECAP-ATOMICS-NEXT:    cret
;
; PURECAP-LIBCALLS-LABEL: atomic_cap_ptr_xchg_rel:
; PURECAP-LIBCALLS:       # %bb.0:
; PURECAP-LIBCALLS-NEXT:    cincoffset csp, csp, -16
; PURECAP-LIBCALLS-NEXT:    csc cra, 8(csp) # 8-byte Folded Spill
; PURECAP-LIBCALLS-NEXT:    li a2, 3
; PURECAP-LIBCALLS-NEXT:    ccall __atomic_exchange_cap
; PURECAP-LIBCALLS-NEXT:    clc cra, 8(csp) # 8-byte Folded Reload
; PURECAP-LIBCALLS-NEXT:    cincoffset csp, csp, 16
; PURECAP-LIBCALLS-NEXT:    cret
;
; HYBRID-LABEL: atomic_cap_ptr_xchg_rel:
; HYBRID:       # %bb.0:
; HYBRID-NEXT:    addi sp, sp, -16
; HYBRID-NEXT:    sw ra, 12(sp) # 4-byte Folded Spill
; HYBRID-NEXT:    li a2, 3
; HYBRID-NEXT:    call __atomic_exchange_cap_c@plt
; HYBRID-NEXT:    lw ra, 12(sp) # 4-byte Folded Reload
; HYBRID-NEXT:    addi sp, sp, 16
; HYBRID-NEXT:    ret
  %tmp = atomicrmw xchg i32 addrspace(200)* addrspace(200)* %ptr, i32 addrspace(200)* %val release
  ret i32 addrspace(200)* %tmp
}

define i32 addrspace(200)* @atomic_cap_ptr_xchg_acq_rel(i32 addrspace(200)* addrspace(200)* %ptr, i32 addrspace(200)* %val) nounwind {
; PURECAP-ATOMICS-LABEL: atomic_cap_ptr_xchg_acq_rel:
; PURECAP-ATOMICS:       # %bb.0:
; PURECAP-ATOMICS-NEXT:    camoswap.c.aqrl ca0, ca1, (ca0)
; PURECAP-ATOMICS-NEXT:    cret
;
; PURECAP-LIBCALLS-LABEL: atomic_cap_ptr_xchg_acq_rel:
; PURECAP-LIBCALLS:       # %bb.0:
; PURECAP-LIBCALLS-NEXT:    cincoffset csp, csp, -16
; PURECAP-LIBCALLS-NEXT:    csc cra, 8(csp) # 8-byte Folded Spill
; PURECAP-LIBCALLS-NEXT:    li a2, 4
; PURECAP-LIBCALLS-NEXT:    ccall __atomic_exchange_cap
; PURECAP-LIBCALLS-NEXT:    clc cra, 8(csp) # 8-byte Folded Reload
; PURECAP-LIBCALLS-NEXT:    cincoffset csp, csp, 16
; PURECAP-LIBCALLS-NEXT:    cret
;
; HYBRID-LABEL: atomic_cap_ptr_xchg_acq_rel:
; HYBRID:       # %bb.0:
; HYBRID-NEXT:    addi sp, sp, -16
; HYBRID-NEXT:    sw ra, 12(sp) # 4-byte Folded Spill
; HYBRID-NEXT:    li a2, 4
; HYBRID-NEXT:    call __atomic_exchange_cap_c@plt
; HYBRID-NEXT:    lw ra, 12(sp) # 4-byte Folded Reload
; HYBRID-NEXT:    addi sp, sp, 16
; HYBRID-NEXT:    ret
  %tmp = atomicrmw xchg i32 addrspace(200)* addrspace(200)* %ptr, i32 addrspace(200)* %val acq_rel
  ret i32 addrspace(200)* %tmp
}

; Also check non-i8* xchg:
define i32 addrspace(200)* @atomic_cap_ptr_xchg_i32ptr(i32 addrspace(200)* addrspace(200)* %ptr, i32 addrspace(200)* %val) nounwind {
; PURECAP-ATOMICS-LABEL: atomic_cap_ptr_xchg_i32ptr:
; PURECAP-ATOMICS:       # %bb.0:
; PURECAP-ATOMICS-NEXT:    camoswap.c.aqrl ca0, ca1, (ca0)
; PURECAP-ATOMICS-NEXT:    cret
;
; PURECAP-LIBCALLS-LABEL: atomic_cap_ptr_xchg_i32ptr:
; PURECAP-LIBCALLS:       # %bb.0:
; PURECAP-LIBCALLS-NEXT:    cincoffset csp, csp, -16
; PURECAP-LIBCALLS-NEXT:    csc cra, 8(csp) # 8-byte Folded Spill
; PURECAP-LIBCALLS-NEXT:    li a2, 4
; PURECAP-LIBCALLS-NEXT:    ccall __atomic_exchange_cap
; PURECAP-LIBCALLS-NEXT:    clc cra, 8(csp) # 8-byte Folded Reload
; PURECAP-LIBCALLS-NEXT:    cincoffset csp, csp, 16
; PURECAP-LIBCALLS-NEXT:    cret
;
; HYBRID-LABEL: atomic_cap_ptr_xchg_i32ptr:
; HYBRID:       # %bb.0:
; HYBRID-NEXT:    addi sp, sp, -16
; HYBRID-NEXT:    sw ra, 12(sp) # 4-byte Folded Spill
; HYBRID-NEXT:    li a2, 4
; HYBRID-NEXT:    call __atomic_exchange_cap_c@plt
; HYBRID-NEXT:    lw ra, 12(sp) # 4-byte Folded Reload
; HYBRID-NEXT:    addi sp, sp, 16
; HYBRID-NEXT:    ret
  %tmp = atomicrmw xchg i32 addrspace(200)* addrspace(200)* %ptr, i32 addrspace(200)* %val acq_rel
  ret i32 addrspace(200)* %tmp
}

define i32 addrspace(200)* @atomic_cap_ptr_add(i32 addrspace(200)* addrspace(200)* %ptr, i32 addrspace(200)* %val) nounwind {
; PURECAP-ATOMICS-LABEL: atomic_cap_ptr_add:
; PURECAP-ATOMICS:       # %bb.0:
; PURECAP-ATOMICS-NEXT:  .LBB6_1: # =>This Inner Loop Header: Depth=1
; PURECAP-ATOMICS-NEXT:    clr.c.aqrl ca2, (ca0)
; PURECAP-ATOMICS-NEXT:    cincoffset ca3, ca2, a1
; PURECAP-ATOMICS-NEXT:    csc.c.aqrl a3, ca3, (ca0)
; PURECAP-ATOMICS-NEXT:    bnez a3, .LBB6_1
; PURECAP-ATOMICS-NEXT:  # %bb.2:
; PURECAP-ATOMICS-NEXT:    cmove ca0, ca2
; PURECAP-ATOMICS-NEXT:    cret
;
; PURECAP-LIBCALLS-LABEL: atomic_cap_ptr_add:
; PURECAP-LIBCALLS:       # %bb.0:
; PURECAP-LIBCALLS-NEXT:    cincoffset csp, csp, -48
; PURECAP-LIBCALLS-NEXT:    csc cra, 40(csp) # 8-byte Folded Spill
; PURECAP-LIBCALLS-NEXT:    csc cs0, 32(csp) # 8-byte Folded Spill
; PURECAP-LIBCALLS-NEXT:    csc cs1, 24(csp) # 8-byte Folded Spill
; PURECAP-LIBCALLS-NEXT:    csc cs2, 16(csp) # 8-byte Folded Spill
; PURECAP-LIBCALLS-NEXT:    cmove cs0, ca0
; PURECAP-LIBCALLS-NEXT:    clc ca3, 0(ca0)
; PURECAP-LIBCALLS-NEXT:    cgetaddr s2, ca1
; PURECAP-LIBCALLS-NEXT:    cincoffset ca0, csp, 8
; PURECAP-LIBCALLS-NEXT:    csetbounds cs1, ca0, 8
; PURECAP-LIBCALLS-NEXT:  .LBB6_1: # %atomicrmw.start
; PURECAP-LIBCALLS-NEXT:    # =>This Inner Loop Header: Depth=1
; PURECAP-LIBCALLS-NEXT:    cgetaddr a0, ca3
; PURECAP-LIBCALLS-NEXT:    add a0, a0, s2
; PURECAP-LIBCALLS-NEXT:    csetaddr ca2, ca3, a0
; PURECAP-LIBCALLS-NEXT:    csc ca3, 8(csp)
; PURECAP-LIBCALLS-NEXT:    addi a3, zero, 5
; PURECAP-LIBCALLS-NEXT:    addi a4, zero, 5
; PURECAP-LIBCALLS-NEXT:    cmove ca0, cs0
; PURECAP-LIBCALLS-NEXT:    cmove ca1, cs1
; PURECAP-LIBCALLS-NEXT:    ccall __atomic_compare_exchange_cap
; PURECAP-LIBCALLS-NEXT:    clc ca3, 8(csp)
; PURECAP-LIBCALLS-NEXT:    beqz a0, .LBB6_1
; PURECAP-LIBCALLS-NEXT:  # %bb.2: # %atomicrmw.end
; PURECAP-LIBCALLS-NEXT:    cmove ca0, ca3
; PURECAP-LIBCALLS-NEXT:    clc cs2, 16(csp) # 8-byte Folded Reload
; PURECAP-LIBCALLS-NEXT:    clc cs1, 24(csp) # 8-byte Folded Reload
; PURECAP-LIBCALLS-NEXT:    clc cs0, 32(csp) # 8-byte Folded Reload
; PURECAP-LIBCALLS-NEXT:    clc cra, 40(csp) # 8-byte Folded Reload
; PURECAP-LIBCALLS-NEXT:    cincoffset csp, csp, 48
; PURECAP-LIBCALLS-NEXT:    cret
;
; HYBRID-LABEL: atomic_cap_ptr_add:
; HYBRID:       # %bb.0:
; HYBRID-NEXT:    addi sp, sp, -32
; HYBRID-NEXT:    sw ra, 28(sp) # 4-byte Folded Spill
; HYBRID-NEXT:    sw s0, 24(sp) # 4-byte Folded Spill
; HYBRID-NEXT:    sc ca0, 8(sp) # 8-byte Folded Spill
; HYBRID-NEXT:    lc.cap ca3, (ca0)
; HYBRID-NEXT:    cgetaddr s0, ca1
; HYBRID-NEXT:  .LBB6_1: # %atomicrmw.start
; HYBRID-NEXT:    # =>This Inner Loop Header: Depth=1
; HYBRID-NEXT:    cgetaddr a0, ca3
; HYBRID-NEXT:    add a0, a0, s0
; HYBRID-NEXT:    csetaddr ca2, ca3, a0
; HYBRID-NEXT:    sc ca3, 16(sp)
; HYBRID-NEXT:    addi a1, sp, 16
; HYBRID-NEXT:    addi a3, zero, 5
; HYBRID-NEXT:    addi a4, zero, 5
; HYBRID-NEXT:    lc ca0, 8(sp) # 8-byte Folded Reload
; HYBRID-NEXT:    call __atomic_compare_exchange_cap_c@plt
; HYBRID-NEXT:    lc ca3, 16(sp)
; HYBRID-NEXT:    beqz a0, .LBB6_1
; HYBRID-NEXT:  # %bb.2: # %atomicrmw.end
; HYBRID-NEXT:    cmove ca0, ca3
; HYBRID-NEXT:    lw s0, 24(sp) # 4-byte Folded Reload
; HYBRID-NEXT:    lw ra, 28(sp) # 4-byte Folded Reload
; HYBRID-NEXT:    addi sp, sp, 32
; HYBRID-NEXT:    ret
  %tmp = atomicrmw add i32 addrspace(200)* addrspace(200)* %ptr, i32 addrspace(200)* %val seq_cst
  ret i32 addrspace(200)* %tmp
}

define i32 addrspace(200)* @atomic_cap_ptr_sub(i32 addrspace(200)* addrspace(200)* %ptr, i32 addrspace(200)* %val) nounwind {
; PURECAP-ATOMICS-LABEL: atomic_cap_ptr_sub:
; PURECAP-ATOMICS:       # %bb.0:
; PURECAP-ATOMICS-NEXT:  .LBB7_1: # =>This Inner Loop Header: Depth=1
; PURECAP-ATOMICS-NEXT:    clr.c.aqrl ca2, (ca0)
; PURECAP-ATOMICS-NEXT:    sub a3, a2, a1
; PURECAP-ATOMICS-NEXT:    csetaddr ca3, ca2, a3
; PURECAP-ATOMICS-NEXT:    csc.c.aqrl a3, ca3, (ca0)
; PURECAP-ATOMICS-NEXT:    bnez a3, .LBB7_1
; PURECAP-ATOMICS-NEXT:  # %bb.2:
; PURECAP-ATOMICS-NEXT:    cmove ca0, ca2
; PURECAP-ATOMICS-NEXT:    cret
;
; define i32 addrspace(200)* @atomic_cap_ptr_nand(i32 addrspace(200)* addrspace(200)* %ptr, i32 addrspace(200)* %val) nounwind {
; bb:
;   %tmp = atomicrmw nand i32 addrspace(200)* addrspace(200)* %ptr, i32 addrspace(200)* %val seq_cst
;   ret i32 addrspace(200)* %tmp
; }
;
; define i32 addrspace(200)* @atomic_cap_ptr_or(i32 addrspace(200)* addrspace(200)* %ptr, i32 addrspace(200)* %val) nounwind {
; bb:
;   %tmp = atomicrmw or i32 addrspace(200)* addrspace(200)* %ptr, i32 addrspace(200)* %val seq_cst
;   ret i32 addrspace(200)* %tmp
; }
;
; define i32 addrspace(200)* @atomic_cap_ptr_xor(i32 addrspace(200)* addrspace(200)* %ptr, i32 addrspace(200)* %val) nounwind {
; bb:
;   %tmp = atomicrmw xor i32 addrspace(200)* addrspace(200)* %ptr, i32 addrspace(200)* %val seq_cst
;   ret i32 addrspace(200)* %tmp
; }
;
; HYBRID-LABEL: atomic_cap_ptr_and:
; HYBRID:       # %bb.0:
; HYBRID-NEXT:    addi sp, sp, -32
; HYBRID-NEXT:    sw ra, 28(sp) # 4-byte Folded Spill
; HYBRID-NEXT:    sw s0, 24(sp) # 4-byte Folded Spill
; HYBRID-NEXT:    sc ca0, 8(sp) # 8-byte Folded Spill
; HYBRID-NEXT:    lc.cap ca3, (ca0)
; HYBRID-NEXT:    cgetaddr s0, ca1
; HYBRID-NEXT:  .LBB8_1: # %atomicrmw.start
; HYBRID-NEXT:    # =>This Inner Loop Header: Depth=1
; HYBRID-NEXT:    cgetaddr a0, ca3
; HYBRID-NEXT:    and a0, a0, s0
; HYBRID-NEXT:    csetaddr ca2, ca3, a0
; HYBRID-NEXT:    sc ca3, 16(sp)
; HYBRID-NEXT:    addi a1, sp, 16
; HYBRID-NEXT:    addi a3, zero, 5
; HYBRID-NEXT:    addi a4, zero, 5
; HYBRID-NEXT:    lc ca0, 8(sp) # 8-byte Folded Reload
; HYBRID-NEXT:    call __atomic_compare_exchange_cap_c@plt
; HYBRID-NEXT:    lc ca3, 16(sp)
; HYBRID-NEXT:    beqz a0, .LBB8_1
; HYBRID-NEXT:  # %bb.2: # %atomicrmw.end
; HYBRID-NEXT:    cmove ca0, ca3
; HYBRID-NEXT:    lw s0, 24(sp) # 4-byte Folded Reload
; HYBRID-NEXT:    lw ra, 28(sp) # 4-byte Folded Reload
; HYBRID-NEXT:    addi sp, sp, 32
; HYBRID-NEXT:    ret
  %tmp = atomicrmw and i32 addrspace(200)* addrspace(200)* %ptr, i32 addrspace(200)* %val seq_cst
  ret i32 addrspace(200)* %tmp
}

define i32 addrspace(200)* @atomic_cap_ptr_nand(i32 addrspace(200)* addrspace(200)* %ptr, i32 addrspace(200)* %val) nounwind {
; PURECAP-ATOMICS-LABEL: atomic_cap_ptr_nand:
; PURECAP-ATOMICS:       # %bb.0:
; PURECAP-ATOMICS-NEXT:  .LBB9_1: # =>This Inner Loop Header: Depth=1
; PURECAP-ATOMICS-NEXT:    clr.c.aqrl ca2, (ca0)
; PURECAP-ATOMICS-NEXT:    and a3, a2, a1
; PURECAP-ATOMICS-NEXT:    not a3, a3
; PURECAP-ATOMICS-NEXT:    csetaddr ca3, ca2, a3
; PURECAP-ATOMICS-NEXT:    csc.c.aqrl a3, ca3, (ca0)
; PURECAP-ATOMICS-NEXT:    bnez a3, .LBB9_1
; PURECAP-ATOMICS-NEXT:  # %bb.2:
; PURECAP-ATOMICS-NEXT:    cmove ca0, ca2
; PURECAP-ATOMICS-NEXT:    cret
;
; PURECAP-LIBCALLS-LABEL: atomic_cap_ptr_nand:
; PURECAP-LIBCALLS:       # %bb.0:
; PURECAP-LIBCALLS-NEXT:    cincoffset csp, csp, -48
; PURECAP-LIBCALLS-NEXT:    csc cra, 40(csp) # 8-byte Folded Spill
; PURECAP-LIBCALLS-NEXT:    csc cs0, 32(csp) # 8-byte Folded Spill
; PURECAP-LIBCALLS-NEXT:    csc cs1, 24(csp) # 8-byte Folded Spill
; PURECAP-LIBCALLS-NEXT:    csc cs2, 16(csp) # 8-byte Folded Spill
; PURECAP-LIBCALLS-NEXT:    cmove cs0, ca0
; PURECAP-LIBCALLS-NEXT:    clc ca3, 0(ca0)
; PURECAP-LIBCALLS-NEXT:    cgetaddr s2, ca1
; PURECAP-LIBCALLS-NEXT:    cincoffset ca0, csp, 8
; PURECAP-LIBCALLS-NEXT:    csetbounds cs1, ca0, 8
; PURECAP-LIBCALLS-NEXT:  .LBB9_1: # %atomicrmw.start
; PURECAP-LIBCALLS-NEXT:    # =>This Inner Loop Header: Depth=1
; PURECAP-LIBCALLS-NEXT:    cgetaddr a0, ca3
; PURECAP-LIBCALLS-NEXT:    and a0, a0, s2
; PURECAP-LIBCALLS-NEXT:    not a0, a0
; PURECAP-LIBCALLS-NEXT:    csetaddr ca2, ca3, a0
; PURECAP-LIBCALLS-NEXT:    csc ca3, 8(csp)
; PURECAP-LIBCALLS-NEXT:    addi a3, zero, 5
; PURECAP-LIBCALLS-NEXT:    addi a4, zero, 5
; PURECAP-LIBCALLS-NEXT:    cmove ca0, cs0
; PURECAP-LIBCALLS-NEXT:    cmove ca1, cs1
; PURECAP-LIBCALLS-NEXT:    ccall __atomic_compare_exchange_cap
; PURECAP-LIBCALLS-NEXT:    clc ca3, 8(csp)
; PURECAP-LIBCALLS-NEXT:    beqz a0, .LBB9_1
; PURECAP-LIBCALLS-NEXT:  # %bb.2: # %atomicrmw.end
; PURECAP-LIBCALLS-NEXT:    cmove ca0, ca3
; PURECAP-LIBCALLS-NEXT:    clc cs2, 16(csp) # 8-byte Folded Reload
; PURECAP-LIBCALLS-NEXT:    clc cs1, 24(csp) # 8-byte Folded Reload
; PURECAP-LIBCALLS-NEXT:    clc cs0, 32(csp) # 8-byte Folded Reload
; PURECAP-LIBCALLS-NEXT:    clc cra, 40(csp) # 8-byte Folded Reload
; PURECAP-LIBCALLS-NEXT:    cincoffset csp, csp, 48
; PURECAP-LIBCALLS-NEXT:    cret
;
; HYBRID-LABEL: atomic_cap_ptr_nand:
; HYBRID:       # %bb.0:
; HYBRID-NEXT:    addi sp, sp, -32
; HYBRID-NEXT:    sw ra, 28(sp) # 4-byte Folded Spill
; HYBRID-NEXT:    sw s0, 24(sp) # 4-byte Folded Spill
; HYBRID-NEXT:    sc ca0, 8(sp) # 8-byte Folded Spill
; HYBRID-NEXT:    lc.cap ca3, (ca0)
; HYBRID-NEXT:    cgetaddr s0, ca1
; HYBRID-NEXT:  .LBB9_1: # %atomicrmw.start
; HYBRID-NEXT:    # =>This Inner Loop Header: Depth=1
; HYBRID-NEXT:    cgetaddr a0, ca3
; HYBRID-NEXT:    and a0, a0, s0
; HYBRID-NEXT:    not a0, a0
; HYBRID-NEXT:    csetaddr ca2, ca3, a0
; HYBRID-NEXT:    sc ca3, 16(sp)
; HYBRID-NEXT:    addi a1, sp, 16
; HYBRID-NEXT:    addi a3, zero, 5
; HYBRID-NEXT:    addi a4, zero, 5
; HYBRID-NEXT:    lc ca0, 8(sp) # 8-byte Folded Reload
; HYBRID-NEXT:    call __atomic_compare_exchange_cap_c@plt
; HYBRID-NEXT:    lc ca3, 16(sp)
; HYBRID-NEXT:    beqz a0, .LBB9_1
; HYBRID-NEXT:  # %bb.2: # %atomicrmw.end
; HYBRID-NEXT:    cmove ca0, ca3
; HYBRID-NEXT:    lw s0, 24(sp) # 4-byte Folded Reload
; HYBRID-NEXT:    lw ra, 28(sp) # 4-byte Folded Reload
; HYBRID-NEXT:    addi sp, sp, 32
; HYBRID-NEXT:    ret
  %tmp = atomicrmw nand i32 addrspace(200)* addrspace(200)* %ptr, i32 addrspace(200)* %val seq_cst
  ret i32 addrspace(200)* %tmp
}

define i32 addrspace(200)* @atomic_cap_ptr_or(i32 addrspace(200)* addrspace(200)* %ptr, i32 addrspace(200)* %val) nounwind {
; PURECAP-ATOMICS-LABEL: atomic_cap_ptr_or:
; PURECAP-ATOMICS:       # %bb.0:
; PURECAP-ATOMICS-NEXT:  .LBB10_1: # =>This Inner Loop Header: Depth=1
; PURECAP-ATOMICS-NEXT:    clr.c.aqrl ca2, (ca0)
; PURECAP-ATOMICS-NEXT:    or a3, a2, a1
; PURECAP-ATOMICS-NEXT:    csetaddr ca3, ca2, a3
; PURECAP-ATOMICS-NEXT:    csc.c.aqrl a3, ca3, (ca0)
; PURECAP-ATOMICS-NEXT:    bnez a3, .LBB10_1
; PURECAP-ATOMICS-NEXT:  # %bb.2:
; PURECAP-ATOMICS-NEXT:    cmove ca0, ca2
; PURECAP-ATOMICS-NEXT:    cret
;
; PURECAP-LIBCALLS-LABEL: atomic_cap_ptr_umin:
; PURECAP-LIBCALLS:       # %bb.0:
; PURECAP-LIBCALLS-NEXT:    cincoffset csp, csp, -48
; PURECAP-LIBCALLS-NEXT:    csc cra, 40(csp) # 8-byte Folded Spill
; PURECAP-LIBCALLS-NEXT:    csc cs0, 32(csp) # 8-byte Folded Spill
; PURECAP-LIBCALLS-NEXT:    csc cs1, 24(csp) # 8-byte Folded Spill
; PURECAP-LIBCALLS-NEXT:    csc cs2, 16(csp) # 8-byte Folded Spill
; PURECAP-LIBCALLS-NEXT:    cmove cs2, ca0
; PURECAP-LIBCALLS-NEXT:    clc ca3, 0(ca0)
; PURECAP-LIBCALLS-NEXT:    cmove cs1, ca1
; PURECAP-LIBCALLS-NEXT:    cincoffset ca0, csp, 8
; PURECAP-LIBCALLS-NEXT:    csetbounds cs0, ca0, 8
; PURECAP-LIBCALLS-NEXT:    j .LBB15_2
; PURECAP-LIBCALLS-NEXT:  .LBB15_1: # %atomicrmw.start
; PURECAP-LIBCALLS-NEXT:    # in Loop: Header=BB15_2 Depth=1
; PURECAP-LIBCALLS-NEXT:    csc ca3, 8(csp)
; PURECAP-LIBCALLS-NEXT:    li a3, 5
; PURECAP-LIBCALLS-NEXT:    li a4, 5
; PURECAP-LIBCALLS-NEXT:    cmove ca0, cs2
; PURECAP-LIBCALLS-NEXT:    cmove ca1, cs0
; PURECAP-LIBCALLS-NEXT:    ccall __atomic_compare_exchange_cap
; PURECAP-LIBCALLS-NEXT:    clc ca3, 8(csp)
; PURECAP-LIBCALLS-NEXT:    bnez a0, .LBB15_4
; PURECAP-LIBCALLS-NEXT:  .LBB15_2: # %atomicrmw.start
; PURECAP-LIBCALLS-NEXT:    # =>This Inner Loop Header: Depth=1
; PURECAP-LIBCALLS-NEXT:    sltu a0, s1, a3
; PURECAP-LIBCALLS-NEXT:    xori a0, a0, 1
; PURECAP-LIBCALLS-NEXT:    cmove ca2, ca3
; PURECAP-LIBCALLS-NEXT:    bnez a0, .LBB15_1
; PURECAP-LIBCALLS-NEXT:  # %bb.3: # %atomicrmw.start
; PURECAP-LIBCALLS-NEXT:    # in Loop: Header=BB15_2 Depth=1
; PURECAP-LIBCALLS-NEXT:    cmove ca2, cs1
; PURECAP-LIBCALLS-NEXT:    j .LBB15_1
; PURECAP-LIBCALLS-NEXT:  .LBB15_4: # %atomicrmw.end
; PURECAP-LIBCALLS-NEXT:    cmove ca0, ca3
; PURECAP-LIBCALLS-NEXT:    clc cra, 40(csp) # 8-byte Folded Reload
; PURECAP-LIBCALLS-NEXT:    clc cs0, 32(csp) # 8-byte Folded Reload
; PURECAP-LIBCALLS-NEXT:    clc cs1, 24(csp) # 8-byte Folded Reload
; PURECAP-LIBCALLS-NEXT:    clc cs2, 16(csp) # 8-byte Folded Reload
; PURECAP-LIBCALLS-NEXT:    cincoffset csp, csp, 48
; PURECAP-LIBCALLS-NEXT:    cret
;
; HYBRID-LABEL: atomic_cap_ptr_umin:
; HYBRID:       # %bb.0:
; HYBRID-NEXT:    addi sp, sp, -32
; HYBRID-NEXT:    sw ra, 28(sp) # 4-byte Folded Spill
; HYBRID-NEXT:    sc ca0, 0(sp) # 8-byte Folded Spill
; HYBRID-NEXT:    lc.cap ca3, (ca0)
; HYBRID-NEXT:    sc ca1, 8(sp) # 8-byte Folded Spill
; HYBRID-NEXT:    j .LBB15_2
; HYBRID-NEXT:  .LBB15_1: # %atomicrmw.start
; HYBRID-NEXT:    # in Loop: Header=BB15_2 Depth=1
; HYBRID-NEXT:    sc ca3, 16(sp)
; HYBRID-NEXT:    addi a1, sp, 16
; HYBRID-NEXT:    li a3, 5
; HYBRID-NEXT:    li a4, 5
; HYBRID-NEXT:    lc ca0, 0(sp) # 8-byte Folded Reload
; HYBRID-NEXT:    call __atomic_compare_exchange_cap_c@plt
; HYBRID-NEXT:    lc ca3, 16(sp)
; HYBRID-NEXT:    bnez a0, .LBB15_4
; HYBRID-NEXT:  .LBB15_2: # %atomicrmw.start
; HYBRID-NEXT:    # =>This Inner Loop Header: Depth=1
; HYBRID-NEXT:    lc ca0, 8(sp) # 8-byte Folded Reload
; HYBRID-NEXT:    sltu a0, a0, a3
; HYBRID-NEXT:    xori a0, a0, 1
; HYBRID-NEXT:    cmove ca2, ca3
; HYBRID-NEXT:    bnez a0, .LBB15_1
; HYBRID-NEXT:  # %bb.3: # %atomicrmw.start
; HYBRID-NEXT:    # in Loop: Header=BB15_2 Depth=1
; HYBRID-NEXT:    lc ca2, 8(sp) # 8-byte Folded Reload
; HYBRID-NEXT:    j .LBB15_1
; HYBRID-NEXT:  .LBB15_4: # %atomicrmw.end
; HYBRID-NEXT:    cmove ca0, ca3
; HYBRID-NEXT:    lw ra, 28(sp) # 4-byte Folded Reload
; HYBRID-NEXT:    addi sp, sp, 32
; HYBRID-NEXT:    ret
  %tmp = atomicrmw umin i32 addrspace(200)* addrspace(200)* %ptr, i32 addrspace(200)* %val seq_cst
  ret i32 addrspace(200)* %tmp
}
;; NOTE: These prefixes are unused and the list is autogenerated. Do not add tests below this line:
; HYBRID-ATOMICS: {{.*}}
; HYBRID-LIBCALLS: {{.*}}
; PURECAP: {{.*}}
